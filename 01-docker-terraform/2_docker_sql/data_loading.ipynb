{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import TLC Data\n",
    "Example code to download and import the TLC data from the [TLC Trip Record Data](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page) website into a postgres database.\n",
    "\n",
    "NOTE: Trip data is available in `.parquet` and `.csv` format. This notebook has examples for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from loguru import logger\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a connection to the database\n",
    "engine = create_engine(\"postgresql://root:root@localhost:5432/ny_taxi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Yellow Taxi Trip Data (`.parquet`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 20.6M  100 20.6M    0     0  8973k      0  0:00:02  0:00:02 --:--:-- 8973k0     0  8644k      0  0:00:02  0:00:01  0:00:01 8641k\n"
     ]
    }
   ],
   "source": [
    "!curl -L https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-01.parquet -o yellow_tripdata_2021-01.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"yellow_tripdata_2021-01.parquet\"\n",
    "file = pq.ParquetFile(file_name)\n",
    "# Read first 10 rows to get schema\n",
    "df = next(file.iter_batches(batch_size=10)).to_pandas()\n",
    "df_iter = file.iter_batches(batch_size=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Yellow Taxi Trip Data (`.csv`)\n",
    "Code to download CSV files, uncomment to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -L https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2021-01.csv.gz -o yellow_tripdata_2021-01.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read first 10 rows to get schema\n",
    "# file_name = \"yellow_tripdata_2021-01.csv.gz\"\n",
    "# df = pd.read_csv(file_name, nrows=10)\n",
    "# # CSV reading does not convert to datetime automatically\n",
    "# df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "# df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "# df_iter = pd.read_csv(file_name, iterator=True, chunksize=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load taxi trip data to postgres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"yellow_taxi_data\" (\n",
      "\"VendorID\" INTEGER,\n",
      "  \"tpep_pickup_datetime\" TIMESTAMP,\n",
      "  \"tpep_dropoff_datetime\" TIMESTAMP,\n",
      "  \"passenger_count\" REAL,\n",
      "  \"trip_distance\" REAL,\n",
      "  \"RatecodeID\" REAL,\n",
      "  \"store_and_fwd_flag\" TEXT,\n",
      "  \"PULocationID\" INTEGER,\n",
      "  \"DOLocationID\" INTEGER,\n",
      "  \"payment_type\" INTEGER,\n",
      "  \"fare_amount\" REAL,\n",
      "  \"extra\" REAL,\n",
      "  \"mta_tax\" REAL,\n",
      "  \"tip_amount\" REAL,\n",
      "  \"tolls_amount\" REAL,\n",
      "  \"improvement_surcharge\" REAL,\n",
      "  \"total_amount\" REAL,\n",
      "  \"congestion_surcharge\" REAL,\n",
      "  \"airport_fee\" REAL\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# show the schema\n",
    "print(pd.io.sql.get_schema(df, name=\"yellow_taxi_data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-25 09:34:44.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mInserting batch 1...\u001b[0m\n",
      "\u001b[32m2024-04-25 09:34:56.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mInserted! time taken     12.160 seconds.\n",
      "\u001b[0m\n",
      "\u001b[32m2024-04-25 09:34:56.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mInserting batch 2...\u001b[0m\n",
      "\u001b[32m2024-04-25 09:35:08.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mInserted! time taken     11.960 seconds.\n",
      "\u001b[0m\n",
      "\u001b[32m2024-04-25 09:35:08.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mInserting batch 3...\u001b[0m\n",
      "\u001b[32m2024-04-25 09:35:20.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mInserted! time taken     11.974 seconds.\n",
      "\u001b[0m\n",
      "\u001b[32m2024-04-25 09:35:20.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mInserting batch 4...\u001b[0m\n",
      "\u001b[32m2024-04-25 09:35:33.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mInserted! time taken     12.985 seconds.\n",
      "\u001b[0m\n",
      "\u001b[32m2024-04-25 09:35:33.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mInserting batch 5...\u001b[0m\n",
      "\u001b[32m2024-04-25 09:35:45.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mInserted! time taken     11.909 seconds.\n",
      "\u001b[0m\n",
      "\u001b[32m2024-04-25 09:35:45.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mInserting batch 6...\u001b[0m\n",
      "\u001b[32m2024-04-25 09:35:56.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mInserted! time taken     10.979 seconds.\n",
      "\u001b[0m\n",
      "\u001b[32m2024-04-25 09:35:56.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mInserting batch 7...\u001b[0m\n",
      "\u001b[32m2024-04-25 09:36:07.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mInserted! time taken     11.058 seconds.\n",
      "\u001b[0m\n",
      "\u001b[32m2024-04-25 09:36:07.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mInserting batch 8...\u001b[0m\n",
      "\u001b[32m2024-04-25 09:36:18.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mInserted! time taken     10.796 seconds.\n",
      "\u001b[0m\n",
      "\u001b[32m2024-04-25 09:36:18.496\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mInserting batch 9...\u001b[0m\n",
      "\u001b[32m2024-04-25 09:36:29.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mInserted! time taken     11.346 seconds.\n",
      "\u001b[0m\n",
      "\u001b[32m2024-04-25 09:36:29.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mInserting batch 10...\u001b[0m\n",
      "\u001b[32m2024-04-25 09:36:40.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mInserted! time taken     10.758 seconds.\n",
      "\u001b[0m\n",
      "\u001b[32m2024-04-25 09:36:40.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mInserting batch 11...\u001b[0m\n",
      "\u001b[32m2024-04-25 09:36:51.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mInserted! time taken     11.135 seconds.\n",
      "\u001b[0m\n",
      "\u001b[32m2024-04-25 09:36:51.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mInserting batch 12...\u001b[0m\n",
      "\u001b[32m2024-04-25 09:37:03.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mInserted! time taken     11.837 seconds.\n",
      "\u001b[0m\n",
      "\u001b[32m2024-04-25 09:37:03.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mInserting batch 13...\u001b[0m\n",
      "\u001b[32m2024-04-25 09:37:15.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mInserted! time taken     12.078 seconds.\n",
      "\u001b[0m\n",
      "\u001b[32m2024-04-25 09:37:15.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mInserting batch 14...\u001b[0m\n",
      "\u001b[32m2024-04-25 09:37:22.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mInserted! time taken      6.718 seconds.\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed! Total time taken was    157.888 seconds for 14 batches.\n"
     ]
    }
   ],
   "source": [
    "# Create the table in the database\n",
    "df.head(0).to_sql(name=\"yellow_taxi_data\", con=engine, if_exists=\"replace\")\n",
    "\n",
    "# Insert values\n",
    "t_start = time()\n",
    "count = 0\n",
    "\n",
    "for batch in df_iter:\n",
    "    count += 1\n",
    "\n",
    "    if \".parquet\" in file_name:\n",
    "        batch_df = batch.to_pandas()\n",
    "    else:\n",
    "        batch_df = batch\n",
    "        # CSV reading does not convert to datetime automatically\n",
    "        batch_df.tpep_pickup_datetime = pd.to_datetime(batch_df.tpep_pickup_datetime)\n",
    "        batch_df.tpep_dropoff_datetime = pd.to_datetime(batch_df.tpep_dropoff_datetime)\n",
    "\n",
    "    logger.info(f\"Inserting batch {count}...\")\n",
    "    b_start = time()\n",
    "    batch_df.to_sql(name=\"yellow_taxi_data\", con=engine, if_exists=\"append\")\n",
    "    b_end = time()\n",
    "    logger.info(f\"Inserted! time taken {b_end-b_start:10.3f} seconds.\\n\")\n",
    "\n",
    "t_end = time()\n",
    "print(\n",
    "    f\"Completed! Total time taken was {t_end-t_start:10.3f} seconds for {count} batches.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxi Zone Lookup Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv -o taxi_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = pd.read_csv(\"taxi_zone_lookup.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the schema\n",
    "print(pd.io.sql.get_schema(df_zones, name=\"zones\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones.to_sql(name=\"zones\", con=engine, if_exists=\"replace\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docker-sql-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
